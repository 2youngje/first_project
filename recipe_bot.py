import os
import uuid
from typing import List

import streamlit as st
from dotenv import load_dotenv

# LangChain ë° Chroma ê´€ë ¨ ëª¨ë“ˆ
from langchain_core.documents import Document
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_chroma import Chroma

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

from langchain_community.document_loaders import PyPDFLoader
import tempfile

# .env íŒŒì¼ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
api_key = os.getenv("UPSTAGE_API_KEY")

# ì„¸ì…˜ ì´ˆê¸°í™” (Streamlitì´ ìƒíƒœ ê¸°ì–µí•˜ë„ë¡ ì„¤ì •)
if "messages" not in st.session_state:
    st.session_state.messages = []
if "id" not in st.session_state:
    st.session_state.id = uuid.uuid4()
    
# ì‚¬ì´ë“œë°”: PDF ì—…ë¡œë“œ
st.sidebar.header("ğŸ“ ë ˆì‹œí”¼ PDF ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type="pdf")

# PDF ë¬¸ì„œ -> List[Document] ë³€í™˜
if uploaded_file is not None:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        tmp_path = tmp_file.name

    loader = PyPDFLoader(tmp_path)
    recipes: List[Document] = loader.load()  # âœ… ì´ ì¤„ì´ í•µì‹¬: ì—…ë¡œë“œëœ PDFê°€ recipesê°€ ë¨
    st.sidebar.success("âœ… PDFì—ì„œ ë ˆì‹œí”¼ ë¡œë”© ì™„ë£Œ!")

    # 3. ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
    vectorstore = Chroma.from_documents(recipes, UpstageEmbeddings(model="solar-embedding-1-large"))
    retriever = vectorstore.as_retriever(k=2)

    # ì´í•˜ ê·¸ëŒ€ë¡œ RAG ì²´ì¸ êµ¬ì„±, ì±„íŒ… ë¡œì§ ë“± ì‚¬ìš© ê°€ëŠ¥
    ...
else:
    st.warning("ğŸ‘ˆ ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    st.stop()

# ì•± ì œëª© ë° ì•ˆë‚´ ë¬¸êµ¬ ì¶œë ¥
st.title("ğŸ³ ì§‘ì—ì„œ ë§Œë“¤ì–´ ë¨¹ëŠ” ìš”ë¦¬ ë ˆì‹œí”¼ ì±—ë´‡")
st.markdown("ì˜ˆ: â€˜ê¹€ì¹˜ë³¶ìŒë°¥ ë§Œë“œëŠ” ë²• ì•Œë ¤ì¤˜â€™, â€˜ë‘ë¶€ë¡œ ë§Œë“¤ ìˆ˜ ìˆëŠ” ìš”ë¦¬ ìˆì–´?â€™")

# ë ˆì‹œí”¼ ë¬¸ì„œ ì •ì˜ (ê³ ì •ëœ ë¬¸ì„œë“¤) -> ì´ ê¸°ëŠ¥ì„ pdfë¥¼ ê°€ì ¸ì™€ì„œ ì‹¤í–‰í•˜ëŠ” ê³ ë„í™”ë¥¼ ì§„í–‰í•´ì•¼í•œë‹¤....
# recipes: List[Document] = [
#     Document(page_content="ê¹€ì¹˜ë³¶ìŒë°¥: ë°¥, ê¹€ì¹˜, ì°¸ê¸°ë¦„, ê°„ì¥, ì„¤íƒ•, ëŒ€íŒŒ, ê³„ë€ì„ ì‚¬ìš©í•´ ë³¶ìŒë°¥ì„ ë§Œë“ ë‹¤."),
#     Document(page_content="ëœì¥ì°Œê°œ: ëœì¥, ë‘ë¶€, ì• í˜¸ë°•, ì–‘íŒŒ, ê³ ì¶”, ë§ˆëŠ˜ ë“±ì„ ë„£ê³  ë“ì¸ë‹¤."),
#     Document(page_content="ê³„ë€ë§ì´: ê³„ë€, ë‹¹ê·¼, íŒŒ, ì†Œê¸ˆì„ ë„£ê³  ì–‡ê²Œ ë¶€ì³ ëŒëŒ ë§Œë‹¤."),
#     Document(page_content="ë¶€ì¹¨ê°œ: ë¶€ì¹¨ê°€ë£¨, ë¬¼, ì•¼ì±„(ë¶€ì¶”, ì–‘íŒŒ ë“±), ì†Œê¸ˆì„ ë„£ê³  íŒ¬ì— ë¶€ì³ ì™„ì„±."),
#     Document(page_content="ë–¡ë³¶ì´: ë–¡, ê³ ì¶”ì¥, ê³ ì¶§ê°€ë£¨, ì–´ë¬µ, ì–‘íŒŒ, ì„¤íƒ•ì„ ë„£ê³  ìì‘í•˜ê²Œ ë“ì¸ë‹¤."),
# ]
# ì´ ë¶€ë¶„ì€ ì‚¬ì´ë“œ ë°”ê°€ ë˜ëŠ” ê²ƒì´ë‹¤.

# ë¬¸ì„œë¥¼ ì„ë² ë”©í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± (Chroma + Solar ì„ë² ë”©)
vectorstore = Chroma.from_documents(recipes, UpstageEmbeddings(model="solar-embedding-1-large"))

# ê²€ìƒ‰ ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì„±
retriever = vectorstore.as_retriever(k=2)

# Solar ê¸°ë°˜ ì±—ë´‡ ê°ì²´ ìƒì„±
chat = ChatUpstage(upstage_api_key=api_key)

# ì§ˆë¬¸ ì¬êµ¬ì„±ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
contextualize_q_system_prompt = """ì‚¬ìš©ìì˜ ìš”ë¦¬ ê´€ë ¨ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™”ì™€ ê´€ë ¨ì´ ìˆìœ¼ë©´, ë…ë¦½ì ì¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ êµ¬ì„±í•˜ì„¸ìš”. ë‹µë³€ì€ í•˜ì§€ ë§ˆì„¸ìš”."""

# ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë°˜ì˜í•œ ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì„±
contextualize_q_prompt = ChatPromptTemplate.from_messages([
    ("system", contextualize_q_system_prompt),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}")
])
history_aware_retriever = create_history_aware_retriever(chat, retriever, contextualize_q_prompt)

# ìš”ë¦¬ ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ ì—­í• ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
qa_system_prompt = """ìš”ë¦¬ ì „ë¬¸ê°€ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ ì œê³µëœ ë ˆì‹œí”¼ ë‚´ìš©ì„ í™œìš©í•˜ì„¸ìš”. ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ê³ , ë‹µë³€ì€ ì„¸ ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
ğŸ“ë‹µë³€ ë‚´ìš©:
ğŸ“ì¦ê±°:
{context}
"""

# ë¬¸ì„œì™€ í•¨ê»˜ ë‹µë³€ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
qa_prompt = ChatPromptTemplate.from_messages([
    ("system", qa_system_prompt),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}")
])

# ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ ìƒì„± ì²´ì¸ êµ¬ì„± (RAG)
question_answer_chain = create_stuff_documents_chain(chat, qa_prompt)
rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)

# ê¸°ì¡´ ëŒ€í™” ë©”ì‹œì§€ë¥¼ UIì— ì¶œë ¥
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ ì²˜ë¦¬
if prompt := st.chat_input("ìš”ë¦¬ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê±¸ ë¬¼ì–´ë³´ì„¸ìš”!"):
    # ì…ë ¥ëœ ì§ˆë¬¸ì„ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})

    # ì‚¬ìš©ì ì§ˆë¬¸ ì¶œë ¥
    with st.chat_message("user"):
        st.markdown(prompt)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ìƒì„± ë° ì¶œë ¥
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        # RAG ì²´ì¸ í˜¸ì¶œ
        result = rag_chain.invoke({
            "input": prompt,
            "chat_history": st.session_state.messages,
        })

        # ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© í¼ì³ë³´ê¸°
        with st.expander("ğŸ” ì°¸ê³ í•œ ë ˆì‹œí”¼ ë¬¸ì„œ ë³´ê¸°"):
            st.write(result["context"])

        # ì‘ë‹µì„ í•œ ë‹¨ì–´ì”© ì¶œë ¥ (íƒ€ì ì¹˜ëŠ” íš¨ê³¼)
        for chunk in result["answer"].split(" "):
            full_response += chunk + " "
            message_placeholder.markdown(full_response + "â–Œ")
        message_placeholder.markdown(full_response)

    # ì–´ì‹œìŠ¤í„´íŠ¸ ë‹µë³€ ì €ì¥
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # ì£¼ì„ ì¶”ê°€